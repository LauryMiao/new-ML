{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification of text documents using sparse features\n",
    "\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices.\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset. It will be\n",
    "automatically downloaded, then cached.\n",
    "\n",
    "The bar plot indicates the accuracy, training time (normalized) and test time\n",
    "(normalized) of each classifier.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "2017-10-24 03:24:19,754 INFO Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
      "2017-10-24 03:24:19,759 INFO Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --all_categories      Whether to use all categories or not.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "  --filtered            Remove newsgroup information that is easily overfit:\n",
      "                        headers, signatures, and quoting.\n",
      "\n",
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "data loaded\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.992612s at 4.009MB/s\n",
      "n_samples: 2034, n_features: 33809\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.424161s at 6.760MB/s\n",
      "n_samples: 1353, n_features: 33809\n",
      "\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.610s\n",
      "test time:  0.002s\n",
      "accuracy:   0.898\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=50, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "train time: 0.327s\n",
      "test time:  0.005s\n",
      "accuracy:   0.885\n",
      "dimensionality: 33809\n",
      "density: 0.240165\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=50, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "train time: 0.380s\n",
      "test time:  0.004s\n",
      "accuracy:   0.902\n",
      "dimensionality: 33809\n",
      "density: 0.698350\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.003s\n",
      "test time:  0.368s\n",
      "accuracy:   0.858\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 2.314s\n",
      "test time:  0.120s\n",
      "accuracy:   0.836\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.342s\n",
      "test time:  0.004s\n",
      "accuracy:   0.900\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.333s\n",
      "test time:  0.004s\n",
      "accuracy:   0.901\n",
      "dimensionality: 33809\n",
      "density: 0.665991\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.389s\n",
      "test time:  0.002s\n",
      "accuracy:   0.873\n",
      "dimensionality: 33809\n",
      "density: 0.005583\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.465s\n",
      "test time:  0.003s\n",
      "accuracy:   0.886\n",
      "dimensionality: 33809\n",
      "density: 0.019862\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.660s\n",
      "test time:  0.002s\n",
      "accuracy:   0.900\n",
      "dimensionality: 33809\n",
      "density: 0.188197\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.023s\n",
      "test time:  0.003s\n",
      "accuracy:   0.855\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.010s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.012s\n",
      "test time:  0.011s\n",
      "accuracy:   0.884\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 0.294s\n",
      "test time:  0.004s\n",
      "accuracy:   0.880\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGZckSZJ68v8BDuBlYAPDhqQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a45dc6908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\",\n",
    "              help=\"Print a detailed classification report.\")\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class\"\n",
    "                   \" for every classifier.\")\n",
    "op.add_option(\"--all_categories\",\n",
    "              action=\"store_true\", dest=\"all_categories\",\n",
    "              help=\"Whether to use all categories or not.\")\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")\n",
    "op.add_option(\"--filtered\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Remove newsgroup information that is easily overfit: \"\n",
    "                   \"headers, signatures, and quoting.\")\n",
    "\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "\n",
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "print()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "if opts.all_categories:\n",
    "    categories = None\n",
    "else:\n",
    "    categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "\n",
    "if opts.filtered:\n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "else:\n",
    "    remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
    "                                   n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1],\n",
       "       [-2, -1],\n",
       "       [-3, -2],\n",
       "       [ 1,  1],\n",
       "       [ 2,  1],\n",
       "       [ 3,  2]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'and': 0,\n",
       "  'document': 1,\n",
       "  'first': 2,\n",
       "  'is': 3,\n",
       "  'one': 4,\n",
       "  'second': 5,\n",
       "  'the': 6,\n",
       "  'third': 7,\n",
       "  'this': 8},\n",
       " array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_,X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (\n",
    "    ['this', 'is', 'text', 'document', 'to', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (\n",
    "    ['this', 'is','a', 'text', 'document', 'to', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  6,  9],\n",
       "       [12, 15, 18, 21],\n",
       "       [24, 27, 30, 33],\n",
       "       [36, 39, 42, 45]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "one_image = np.arange(4 * 4 * 3).reshape((4, 4, 3))\n",
    "one_image[:, :, 0]  # R channel of a fake RGB picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4 * 4 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2, 2, 3), array([[[ 0,  3],\n",
       "         [12, 15]],\n",
       " \n",
       "        [[15, 18],\n",
       "         [27, 30]]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches = image.extract_patches_2d(one_image, (2, 2), max_patches=2,\n",
    "    random_state=0)\n",
    "patches.shape,patches[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 3.449 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "import jieba  \n",
    "  \n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)  \n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式  \n",
    "  \n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)  \n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式  \n",
    "  \n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式  \n",
    "print(\", \".join(seg_list))  \n",
    "  \n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式  \n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
