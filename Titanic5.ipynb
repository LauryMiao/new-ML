{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "Name_length    891 non-null int64\n",
      "Has_Cabin      891 non-null int64\n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 97.5+ KB\n",
      "   Family_Size  Survived\n",
      "0            1  0.303538\n",
      "1            2  0.552795\n",
      "2            3  0.578431\n",
      "3            4  0.724138\n",
      "4            5  0.200000\n",
      "5            6  0.136364\n",
      "6            7  0.333333\n",
      "7            8  0.000000\n",
      "8           11  0.000000\n",
      "   isAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n",
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.336957\n",
      "          Cat_Fare  Survived\n",
      "0  (-0.001, 7.896]  0.456140\n",
      "1  (7.896, 14.454]  0.406250\n",
      "2   (14.454, 31.5]  0.361905\n",
      "3  (31.5, 512.329]  0.333333\n",
      "           CatAge  Survived\n",
      "0  (-0.001, 19.0]  0.428571\n",
      "1    (19.0, 25.0]  0.329545\n",
      "2    (25.0, 32.0]  0.385027\n",
      "3    (32.0, 40.0]  0.396450\n",
      "4    (40.0, 80.0]  0.374233\n",
      "Sex       female  male\n",
      "Title                 \n",
      "Capt           0     1\n",
      "Col            0     2\n",
      "Countess       1     0\n",
      "Don            0     1\n",
      "Dr             1     6\n",
      "Jonkheer       0     1\n",
      "Lady           1     0\n",
      "Major          0     2\n",
      "Master         0    40\n",
      "Miss         182     0\n",
      "Mlle           2     0\n",
      "Mme            1     0\n",
      "Mr             0   517\n",
      "Mrs          125     0\n",
      "Ms             1     0\n",
      "Rev            0     6\n",
      "Sir            0     1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.702703\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4    Rare  0.347826\n",
      "   Survived  Pclass  Sex  Age  Fare  Embarked  Name_length  Has_Cabin  \\\n",
      "0         0       3    1    1     0         0           23          0   \n",
      "1         1       1    0    2     3         1           51          1   \n",
      "2         1       3    0    1     1         0           22          0   \n",
      "3         1       1    0    2     3         0           44          1   \n",
      "4         0       3    1    2     1         0           24          0   \n",
      "5         0       3    1    2     1         2           16          0   \n",
      "6         0       1    1    3     3         0           23          1   \n",
      "7         0       3    1    0     2         0           30          0   \n",
      "8         1       3    0    1     1         0           49          0   \n",
      "9         1       2    0    0     2         1           35          0   \n",
      "\n",
      "   isAlone  Title  \n",
      "0        0      1  \n",
      "1        0      3  \n",
      "2        1      2  \n",
      "3        0      3  \n",
      "4        1      1  \n",
      "5        1      1  \n",
      "6        1      1  \n",
      "7        0      4  \n",
      "8        0      3  \n",
      "9        0      3  \n",
      "   PassengerId  Pclass  Sex  Age  Fare  Embarked  Name_length  Has_Cabin  \\\n",
      "0          892       3    1    2     0         2           16          0   \n",
      "1          893       3    0    2     0         0           32          0   \n",
      "2          894       2    1    3     1         2           25          0   \n",
      "3          895       3    1    1     1         0           16          0   \n",
      "4          896       3    0    1     1         0           44          0   \n",
      "5          897       3    1    0     1         0           26          0   \n",
      "6          898       3    0    1     0         2           20          0   \n",
      "7          899       2    1    1     2         0           28          0   \n",
      "8          900       3    0    1     0         1           41          0   \n",
      "9          901       3    1    1     2         0           23          0   \n",
      "\n",
      "   isAlone  Title  \n",
      "0        1      1  \n",
      "1        0      3  \n",
      "2        1      1  \n",
      "3        1      1  \n",
      "4        0      3  \n",
      "5        1      1  \n",
      "6        1      2  \n",
      "7        0      1  \n",
      "8        1      3  \n",
      "9        0      1  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "\n",
    "train_set = pd.read_csv('./titanic/train.csv')\n",
    "test_set = pd.read_csv('./titanic/test.csv')\n",
    "\n",
    "full_data = [train_set, test_set]\n",
    "\n",
    "# Some features of my own that I have added in\n",
    "# Gives the length of the name\n",
    "train_set['Name_length'] = train_set['Name'].apply(len)\n",
    "test_set['Name_length'] = test_set['Name'].apply(len)\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train_set['Has_Cabin'] = train_set[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test_set['Has_Cabin'] = test_set[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "train_set.info()\n",
    "for dataset in full_data:\n",
    "    dataset['Family_Size'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "print(train_set[['Family_Size', 'Survived']].groupby(['Family_Size'], as_index=False).mean())\n",
    "for dataset in full_data:\n",
    "    dataset['isAlone'] = 0\n",
    "    dataset.loc[dataset['Family_Size'] == 1, 'isAlone'] = 1\n",
    "print(train_set[['isAlone', 'Survived']].groupby(['isAlone'], as_index=False).mean())\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'].fillna('S')\n",
    "print(train_set[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "train_set['Fare'].fillna(dataset['Fare'].median())\n",
    "train_set['Cat_Fare'] = pd.qcut(dataset['Fare'], 4)\n",
    "print(train_set[['Cat_Fare', 'Survived']].groupby(['Cat_Fare'], as_index=False).mean())\n",
    "for dataset in full_data:\n",
    "    mean = dataset['Age'].mean()\n",
    "    std = dataset['Age'].std()\n",
    "    null_count = dataset['Age'].isnull().sum()\n",
    "\n",
    "    age_null_list = np.random.randint(mean - std, mean + std, size=null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_set['CatAge'] = pd.qcut(train_set['Age'], 5)\n",
    "print(train_set[['CatAge', 'Survived']].groupby(['CatAge'], as_index=False).mean())\n",
    "\n",
    "\n",
    "def get_title(name):\n",
    "    search_t = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if (search_t):\n",
    "        return search_t.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "print(pd.crosstab(train_set['Title'], train_set['Sex']))\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', \\\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print(train_set[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).fillna(0).astype(int)\n",
    "\n",
    "    # Mapping Fare\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0).astype(int)\n",
    "\n",
    "    # Mapping Age\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['Name', 'SibSp', 'Ticket', 'Cabin', 'Parch', 'Family_Size']\n",
    "train_set = train_set.drop(drop_elements, axis=1)\n",
    "train_set = train_set.drop(['PassengerId'], axis=1)\n",
    "train_set = train_set.drop(['CatAge', 'Cat_Fare'], axis=1)\n",
    "\n",
    "test_set = test_set.drop(drop_elements, axis=1)\n",
    "\n",
    "print(train_set.head(10))\n",
    "print(test_set.head(10))\n",
    "\n",
    "train = train_set.values\n",
    "test = test_set.drop(['PassengerId'], axis=1).values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()]\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "X = train[0::, 1::]\n",
    "y = train[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
    "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "candidate_classifier = SVC(probability=True)\n",
    "candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n",
    "y_result = candidate_classifier.predict(test)\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_set[\"PassengerId\"],\n",
    "    \"Survived\": y_result\n",
    "})\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
